# Vestig LLM Prompts
# Use {{token}} for variable substitution
# Supports both string format (legacy) and dict format with system/user keys (M4+)

# Session Ingestion: Extract memories from conversation transcripts
extract_memories_from_session:
  description: >
    Extract discrete, factual memories from conversation transcripts with entity extraction
    and temporal stability classification. Memories should be self-contained and substantive.
  system: |
    You are a memory extraction engine for an agent memory system.
    Your task is to extract discrete, factual memories from conversation transcripts.
    Each memory must be self-contained and include entity extraction and temporal classification.
    Output MUST be valid JSON matching the schema exactly.
    Do NOT extract greetings, small talk, or procedural exchanges - only substantive content.
  user: |
    Extract memories from this conversation chunk.

    GUIDELINES FOR MEMORIES:
    - One clear fact, decision, insight, or knowledge point per memory
    - Self-contained with sufficient context for standalone understanding
    - Substantive content only: technical details, decisions, learnings
    - Skip greetings, small talk, procedural exchanges
    - Preserve key context (who, what, when relevant)
    - Confidence reflects clarity and factuality

    GUIDELINES FOR ENTITIES:
    - Extract entities mentioned in each memory
    - Entity types: PERSON, ORG, SYSTEM, PROJECT, PLACE, SKILL, TOOL, FILE, CONCEPT
    - Only extract entities that are clearly mentioned in the memory
    - Provide text evidence supporting each entity
    - Confidence reflects certainty this is the correct entity type

    GUIDELINES FOR TEMPORAL STABILITY:
    Classify each memory's temporal stability (how it changes over time):
    - "static": Permanent facts that never change
      Examples: dates of birth, historical events, past actions/decisions, completed migrations
      Indicators: "was born", "happened on", "decided to", "renamed", "created in"
    - "dynamic": Current state that may change in the future
      Examples: job titles, system configurations, project status, current locations, version numbers
      Indicators: "is currently", "status:", "works as", "configured to", "running on"
    - "ephemeral": Expected to change soon (hours/days), only when explicitly indicated
      Examples: incident ongoing, temporary workaround, on-call this week, today's deployment status
      Indicators: "today", "this week", "temporary", "incident ongoing", "until Friday"
    - "unknown": Mixed content or uncertain classification
      Examples: memories with both static and dynamic elements, or unclear permanence

    CONVERSATION CHUNK:
    {{content}}

    OUTPUT JSON SCHEMA (must match exactly):
    {
      "memories": [
        {
          "content": "self-contained memory with context",
          "confidence": 0.0-1.0,
          "rationale": "why this matters",
          "temporal_stability": "static|dynamic|ephemeral|unknown",
          "entities": [
            {
              "name": "entity name",
              "type": "PERSON|ORG|SYSTEM|PROJECT|PLACE|SKILL|TOOL|FILE|CONCEPT",
              "confidence": 0.0-1.0,
              "evidence": "text snippet supporting this entity"
            }
          ]
        }
      ]
    }

    Return {"memories": []} if none found.

# M4: Document/Session Summary Generation
# Create grounded summaries from extracted MEMORY nodes
summary_v1:
  description: >
    Create a grounded document/session summary from extracted MEMORY nodes.
    The summary MUST ONLY use provided memory items. 
  system: |
    You are a careful summarization engine for a memory graph.
    You must ONLY use the provided MEMORY items as evidence.
    Do NOT introduce new facts, names, numbers, or claims.
    If information is missing, say so in "open_questions" rather than guessing.
    Output MUST be valid JSON matching the schema.
  user: |
    Create a SUMMARY node for this ingest run.

    Source label: {{source_label}}
    Ingest run id: {{ingest_run_id}}

    MEMORY items (each is atomic; treat them as ground truth):
    {{memory_items}}

    OUTPUT JSON SCHEMA (must match exactly):
    {
      "summary": {
        "title": "string - short descriptive title for this document/session",
        "scope": "INGEST_RUN",
        "overview": "string - 2-4 sentences in plain language",
        "bullets": [
          {
            "text": "string - one key insight or fact",
            "memory_ids": ["mem_xxx", "mem_yyy"]
          }
        ],
        "themes": ["string - short tags, single words or short phrases"],
        "open_questions": ["string - genuine gaps or ambiguities if any"]
      }
    }

    CONSTRAINTS:
    - overview: 2–4 sentences, plain language.
    - bullets: 6–12 bullets. Each bullet must cite 1–4 memory_ids that support it.
    - themes: 3–8 short tags (single words or short phrases).
    - open_questions: empty list unless there are genuine gaps/ambiguities.
    - Do not quote long passages. Do not add commentary about your process.
# Create embedding-optimized summaries from MEMORY nodes
summary_v2:
  description: >
    Generate dense, searchable summaries from MEMORY nodes for embedding retrieval.
    Output must be grounded in provided memories only.
  system: |
    Generate embedding-optimized summaries from provided MEMORY items.
    Rules: Use only provided memories. No invented facts. Prioritize searchable keywords and phrases.
    Output valid JSON matching schema.
  user: |
    Summarize for embedding search.

    Source: {{source_label}}
    Run: {{ingest_run_id}}

    MEMORIES:
    {{memory_items}}

    SCHEMA:
    {
      "summary": {
        "title": "string - descriptive, keyword-rich (8-12 words)",
        "overview": "string - dense 2-3 sentences with key entities, actions, outcomes",
        "bullets": [
          {
            "text": "string - specific insight with entities/numbers",
            "memory_ids": ["mem_xxx"]
          }
        ],
        "themes": ["string - searchable terms"],
        "gaps": ["string - missing info"] 
      }
    }

    OPTIMIZE FOR SEARCH:
    - title: Include main entities, topics, or outcomes
    - overview: Front-load key terms, entities, dates, locations
    - bullets: 6-10 items. Cite 1-3 memory_ids each. Use specific nouns/verbs.
    - themes: 4-8 terms optimized for semantic search
    - gaps: Empty unless critical information missing

    Output JSON only.