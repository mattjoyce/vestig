# Vestig LLM Prompts
# Use {{token}} for variable substitution

# Session Ingestion: Extract memories from conversation transcripts
extract_memories_from_session: |
  Extract discrete, factual memories from this conversation transcript, along with entities mentioned in each memory.

  GUIDELINES FOR MEMORIES:
  - One clear fact, decision, insight, or knowledge point per memory
  - Self-contained with sufficient context for standalone understanding
  - Substantive content only: technical details, decisions, learnings
  - Skip greetings, small talk, procedural exchanges
  - Preserve key context (who, what, when relevant)
  - Confidence reflects clarity and factuality

  GUIDELINES FOR ENTITIES:
  - Extract entities mentioned in each memory
  - Entity types: PERSON, ORG, SYSTEM, PROJECT, PLACE, SKILL, TOOL, FILE, CONCEPT
  - Only extract entities that are clearly mentioned in the memory
  - Provide text evidence supporting each entity
  - Confidence reflects certainty this is the correct entity type

  CONVERSATION CHUNK:
  {{content}}

  OUTPUT (valid JSON only):
  {
    "memories": [
      {
        "content": "self-contained memory with context",
        "confidence": 0.0-1.0,
        "rationale": "why this matters",
        "entities": [
          {
            "name": "entity name",
            "type": "PERSON|ORG|SYSTEM|PROJECT|PLACE|SKILL|TOOL|FILE|CONCEPT",
            "confidence": 0.0-1.0,
            "evidence": "text snippet supporting this entity"
          }
        ]
      }
    ]
  }

  Return {"memories": []} if none found.